/**
 * OpenCode Swarm Plugin Wrapper
 *
 * This is a thin wrapper that shells out to the `swarm` CLI for all tool execution.
 * Generated by: swarm setup
 *
 * The plugin only depends on @opencode-ai/plugin (provided by OpenCode).
 * All tool logic lives in the npm package - this just bridges to it.
 *
 * Environment variables:
 * - OPENCODE_SESSION_ID: Passed to CLI for session state persistence
 * - OPENCODE_MESSAGE_ID: Passed to CLI for context
 * - OPENCODE_AGENT: Passed to CLI for context
 * - SWARM_PROJECT_DIR: Project directory (critical for database path)
 */
import type { Plugin, PluginInput, Hooks } from "@opencode-ai/plugin";
import type { ToolPart } from "@opencode-ai/sdk";
import { tool } from "@opencode-ai/plugin";
import { spawn } from "child_process";
import { appendFileSync, mkdirSync, existsSync } from "node:fs";
import { join } from "node:path";
import { homedir } from "node:os";

const SWARM_CLI = "swarm";

// =============================================================================
// File-based Logging (writes to ~/.config/swarm-tools/logs/)
// =============================================================================

const LOG_DIR = join(homedir(), ".config", "swarm-tools", "logs");
const COMPACTION_LOG = join(LOG_DIR, "compaction.log");

/**
 * Ensure log directory exists
 */
function ensureLogDir(): void {
  if (!existsSync(LOG_DIR)) {
    mkdirSync(LOG_DIR, { recursive: true });
  }
}

/**
 * Log a compaction event to file (JSON lines format, compatible with `swarm log`)
 * 
 * @param level - Log level (info, debug, warn, error)
 * @param msg - Log message
 * @param data - Additional structured data
 */
function logCompaction(
  level: "info" | "debug" | "warn" | "error",
  msg: string,
  data?: Record<string, unknown>,
): void {
  try {
    ensureLogDir();
    const entry = JSON.stringify({
      time: new Date().toISOString(),
      level,
      msg,
      ...data,
    });
    appendFileSync(COMPACTION_LOG, entry + "\n");
  } catch {
    // Silently fail - logging should never break the plugin
  }
}

/**
 * Capture compaction event for evals (non-fatal dynamic import)
 * 
 * Uses dynamic import to avoid circular dependencies and keep the plugin wrapper
 * self-contained. Captures COMPACTION events to session JSONL for eval analysis.
 * 
 * @param sessionID - Session ID
 * @param epicID - Epic ID (or "unknown" if not detected)
 * @param compactionType - Event type (detection_complete, prompt_generated, context_injected)
 * @param payload - Event-specific data (full prompts, detection results, etc.)
 */
async function captureCompaction(
  sessionID: string,
  epicID: string,
  compactionType: "detection_complete" | "prompt_generated" | "context_injected",
  payload: any,
): Promise<void> {
  try {
    // Dynamic import to avoid circular deps (plugin wrapper → src → plugin wrapper)
    const { captureCompactionEvent } = await import("../src/eval-capture");
    captureCompactionEvent({
      session_id: sessionID,
      epic_id: epicID,
      compaction_type: compactionType,
      payload,
    });
  } catch (err) {
    // Non-fatal - capture failures shouldn't break compaction
    logCompaction("warn", "compaction_capture_failed", {
      session_id: sessionID,
      compaction_type: compactionType,
      error: err instanceof Error ? err.message : String(err),
    });
  }
}

// Module-level project directory - set during plugin initialization
// This is CRITICAL: without it, the CLI uses process.cwd() which may be wrong
let projectDirectory: string = process.cwd();

// Module-level SDK client - set during plugin initialization
// Used for scanning session messages during compaction
let sdkClient: any = null;

// =============================================================================
// CLI Execution Helper
// =============================================================================

/**
 * Execute a swarm tool via CLI
 *
 * Spawns `swarm tool <name> --json '<args>'` and returns the result.
 * Passes session context via environment variables.
 * 
 * IMPORTANT: Runs in projectDirectory (set by OpenCode) not process.cwd()
 */
async function execTool(
  name: string,
  args: Record<string, unknown>,
  ctx: { sessionID: string; messageID: string; agent: string },
): Promise<string> {
  return new Promise((resolve, reject) => {
    const hasArgs = Object.keys(args).length > 0;
    const cliArgs = hasArgs
      ? ["tool", name, "--json", JSON.stringify(args)]
      : ["tool", name];

    const proc = spawn(SWARM_CLI, cliArgs, {
      cwd: projectDirectory, // Run in project directory, not plugin directory
      stdio: ["ignore", "pipe", "pipe"],
      env: {
        ...process.env,
        OPENCODE_SESSION_ID: ctx.sessionID,
        OPENCODE_MESSAGE_ID: ctx.messageID,
        OPENCODE_AGENT: ctx.agent,
        SWARM_PROJECT_DIR: projectDirectory, // Also pass as env var
      },
    });

    let stdout = "";
    let stderr = "";

    proc.stdout.on("data", (data) => {
      stdout += data;
    });
    proc.stderr.on("data", (data) => {
      stderr += data;
    });

    proc.on("close", (code) => {
      if (code === 0) {
        // Success - return the JSON output
        try {
          const result = JSON.parse(stdout);
          if (result.success && result.data !== undefined) {
            // Unwrap the data for cleaner tool output
            resolve(
              typeof result.data === "string"
                ? result.data
                : JSON.stringify(result.data, null, 2),
            );
          } else if (!result.success && result.error) {
            // Tool returned an error in JSON format
            // Handle both string errors and object errors with .message
            const errorMsg = typeof result.error === "string" 
              ? result.error 
              : (result.error.message || "Tool execution failed");
            reject(new Error(errorMsg));
          } else {
            resolve(stdout);
          }
        } catch {
          resolve(stdout);
        }
      } else if (code === 2) {
        reject(new Error(`Unknown tool: ${name}`));
      } else if (code === 3) {
        reject(new Error(`Invalid JSON args: ${stderr}`));
      } else {
        // Tool returned error
        try {
          const result = JSON.parse(stdout);
          if (!result.success && result.error) {
            // Handle both string errors and object errors with .message
            const errorMsg = typeof result.error === "string"
              ? result.error
              : (result.error.message || `Tool failed with code ${code}`);
            reject(new Error(errorMsg));
          } else {
            reject(
              new Error(stderr || stdout || `Tool failed with code ${code}`),
            );
          }
        } catch {
          reject(
            new Error(stderr || stdout || `Tool failed with code ${code}`),
          );
        }
      }
    });

    proc.on("error", (err) => {
      if ((err as NodeJS.ErrnoException).code === "ENOENT") {
        reject(
          new Error(
            `swarm CLI not found. Install with: npm install -g opencode-swarm-plugin`,
          ),
        );
      } else {
        reject(err);
      }
    });
  });
}

// =============================================================================
// Beads Tools
// =============================================================================

const hive_create = tool({
  description: "Create a new bead with type-safe validation",
  args: {
    title: tool.schema.string().describe("Bead title"),
    type: tool.schema
      .enum(["bug", "feature", "task", "epic", "chore"])
      .optional()
      .describe("Issue type (default: task)"),
    priority: tool.schema
      .number()
      .min(0)
      .max(3)
      .optional()
      .describe("Priority 0-3 (default: 2)"),
    description: tool.schema.string().optional().describe("Bead description"),
    parent_id: tool.schema
      .string()
      .optional()
      .describe("Parent bead ID for epic children"),
  },
  execute: (args, ctx) => execTool("hive_create", args, ctx),
});

const hive_create_epic = tool({
  description: "Create epic with subtasks in one atomic operation",
  args: {
    epic_title: tool.schema.string().describe("Epic title"),
    epic_description: tool.schema
      .string()
      .optional()
      .describe("Epic description"),
    subtasks: tool.schema
      .array(
        tool.schema.object({
          title: tool.schema.string(),
          priority: tool.schema.number().min(0).max(3).optional(),
          files: tool.schema.array(tool.schema.string()).optional(),
        }),
      )
      .describe("Subtasks to create under the epic"),
  },
  execute: (args, ctx) => execTool("hive_create_epic", args, ctx),
});

const hive_query = tool({
  description: "Query beads with filters (replaces bd list, bd ready, bd wip)",
  args: {
    status: tool.schema
      .enum(["open", "in_progress", "blocked", "closed"])
      .optional()
      .describe("Filter by status"),
    type: tool.schema
      .enum(["bug", "feature", "task", "epic", "chore"])
      .optional()
      .describe("Filter by type"),
    ready: tool.schema
      .boolean()
      .optional()
      .describe("Only show unblocked beads"),
    limit: tool.schema
      .number()
      .optional()
      .describe("Max results (default: 20)"),
  },
  execute: (args, ctx) => execTool("hive_query", args, ctx),
});

const hive_update = tool({
  description: "Update bead status/description",
  args: {
    id: tool.schema.string().describe("Cell ID"),
    status: tool.schema
      .enum(["open", "in_progress", "blocked", "closed"])
      .optional()
      .describe("New status"),
    description: tool.schema.string().optional().describe("New description"),
    priority: tool.schema
      .number()
      .min(0)
      .max(3)
      .optional()
      .describe("New priority"),
  },
  execute: (args, ctx) => execTool("hive_update", args, ctx),
});

const hive_close = tool({
  description: "Close a bead with reason",
  args: {
    id: tool.schema.string().describe("Cell ID"),
    reason: tool.schema.string().describe("Completion reason"),
  },
  execute: (args, ctx) => execTool("hive_close", args, ctx),
});

const hive_start = tool({
  description: "Mark a bead as in-progress",
  args: {
    id: tool.schema.string().describe("Cell ID"),
  },
  execute: (args, ctx) => execTool("hive_start", args, ctx),
});

const hive_ready = tool({
  description: "Get the next ready bead (unblocked, highest priority)",
  args: {},
  execute: (args, ctx) => execTool("hive_ready", args, ctx),
});

const hive_sync = tool({
  description: "Sync beads to git and push (MANDATORY at session end)",
  args: {
    auto_pull: tool.schema.boolean().optional().describe("Pull before sync"),
  },
  execute: (args, ctx) => execTool("hive_sync", args, ctx),
});

const hive_cells = tool({
  description: `Query cells from the hive database with flexible filtering.

USE THIS TOOL TO:
- List all open cells: hive_cells()
- Find cells by status: hive_cells({ status: "in_progress" })
- Find cells by type: hive_cells({ type: "bug" })
- Get a specific cell by partial ID: hive_cells({ id: "mjkmd" })
- Get the next ready (unblocked) cell: hive_cells({ ready: true })
- Combine filters: hive_cells({ status: "open", type: "task" })

RETURNS: Array of cells with id, title, status, priority, type, parent_id, created_at, updated_at

PREFER THIS OVER hive_query when you need to:
- See what work is available
- Check status of multiple cells
- Find cells matching criteria
- Look up a cell by partial ID`,
  args: {
    id: tool.schema.string().optional().describe("Partial or full cell ID to look up"),
    status: tool.schema.enum(["open", "in_progress", "blocked", "closed"]).optional().describe("Filter by status"),
    type: tool.schema.enum(["task", "bug", "feature", "epic", "chore"]).optional().describe("Filter by type"),
    ready: tool.schema.boolean().optional().describe("If true, return only the next unblocked cell"),
    limit: tool.schema.number().optional().describe("Max cells to return (default 20)"),
  },
  execute: (args, ctx) => execTool("hive_cells", args, ctx),
});

const beads_link_thread = tool({
  description: "Add metadata linking bead to Agent Mail thread",
  args: {
    bead_id: tool.schema.string().describe("Cell ID"),
    thread_id: tool.schema.string().describe("Agent Mail thread ID"),
  },
  execute: (args, ctx) => execTool("beads_link_thread", args, ctx),
});

// =============================================================================
// Swarm Mail Tools (Embedded)
// =============================================================================

const swarmmail_init = tool({
  description: "Initialize Swarm Mail session (REQUIRED FIRST)",
  args: {
    project_path: tool.schema.string().describe("Absolute path to the project"),
    agent_name: tool.schema.string().optional().describe("Custom agent name"),
    task_description: tool.schema
      .string()
      .optional()
      .describe("Task description"),
  },
  execute: (args, ctx) => execTool("swarmmail_init", args, ctx),
});

const swarmmail_send = tool({
  description: "Send message to other agents via Swarm Mail",
  args: {
    to: tool.schema
      .array(tool.schema.string())
      .describe("Recipient agent names"),
    subject: tool.schema.string().describe("Message subject"),
    body: tool.schema.string().describe("Message body"),
    thread_id: tool.schema
      .string()
      .optional()
      .describe("Thread ID for grouping"),
    importance: tool.schema
      .enum(["low", "normal", "high", "urgent"])
      .optional()
      .describe("Message importance"),
    ack_required: tool.schema
      .boolean()
      .optional()
      .describe("Require acknowledgment"),
  },
  execute: (args, ctx) => execTool("swarmmail_send", args, ctx),
});

const swarmmail_inbox = tool({
  description: "Fetch inbox (CONTEXT-SAFE: bodies excluded, max 5 messages)",
  args: {
    limit: tool.schema
      .number()
      .max(5)
      .optional()
      .describe("Max messages (max 5)"),
    urgent_only: tool.schema
      .boolean()
      .optional()
      .describe("Only urgent messages"),
  },
  execute: (args, ctx) => execTool("swarmmail_inbox", args, ctx),
});

const swarmmail_read_message = tool({
  description: "Fetch ONE message body by ID",
  args: {
    message_id: tool.schema.number().describe("Message ID"),
  },
  execute: (args, ctx) => execTool("swarmmail_read_message", args, ctx),
});

const swarmmail_reserve = tool({
  description: "Reserve file paths for exclusive editing",
  args: {
    paths: tool.schema
      .array(tool.schema.string())
      .describe("File paths/patterns"),
    ttl_seconds: tool.schema.number().optional().describe("Reservation TTL"),
    exclusive: tool.schema.boolean().optional().describe("Exclusive lock"),
    reason: tool.schema.string().optional().describe("Reservation reason"),
  },
  execute: (args, ctx) => execTool("swarmmail_reserve", args, ctx),
});

const swarmmail_release = tool({
  description: "Release file reservations",
  args: {
    paths: tool.schema
      .array(tool.schema.string())
      .optional()
      .describe("Paths to release"),
    reservation_ids: tool.schema
      .array(tool.schema.number())
      .optional()
      .describe("Reservation IDs"),
  },
  execute: (args, ctx) => execTool("swarmmail_release", args, ctx),
});

const swarmmail_ack = tool({
  description: "Acknowledge a message",
  args: {
    message_id: tool.schema.number().describe("Message ID"),
  },
  execute: (args, ctx) => execTool("swarmmail_ack", args, ctx),
});

const swarmmail_health = tool({
  description: "Check Swarm Mail database health",
  args: {},
  execute: (args, ctx) => execTool("swarmmail_health", args, ctx),
});

// =============================================================================
// Structured Tools
// =============================================================================

const structured_extract_json = tool({
  description: "Extract JSON from markdown/text response",
  args: {
    text: tool.schema.string().describe("Text containing JSON"),
  },
  execute: (args, ctx) => execTool("structured_extract_json", args, ctx),
});

const structured_validate = tool({
  description: "Validate agent response against a schema",
  args: {
    response: tool.schema.string().describe("Agent response to validate"),
    schema_name: tool.schema
      .enum(["evaluation", "task_decomposition", "cell_tree"])
      .describe("Schema to validate against"),
    max_retries: tool.schema
      .number()
      .min(1)
      .max(5)
      .optional()
      .describe("Max retries"),
  },
  execute: (args, ctx) => execTool("structured_validate", args, ctx),
});

const structured_parse_evaluation = tool({
  description: "Parse and validate evaluation response",
  args: {
    response: tool.schema.string().describe("Agent response"),
  },
  execute: (args, ctx) => execTool("structured_parse_evaluation", args, ctx),
});

const structured_parse_decomposition = tool({
  description: "Parse and validate task decomposition response",
  args: {
    response: tool.schema.string().describe("Agent response"),
  },
  execute: (args, ctx) => execTool("structured_parse_decomposition", args, ctx),
});

const structured_parse_cell_tree = tool({
  description: "Parse and validate bead tree response",
  args: {
    response: tool.schema.string().describe("Agent response"),
  },
  execute: (args, ctx) => execTool("structured_parse_cell_tree", args, ctx),
});

// =============================================================================
// Swarm Tools
// =============================================================================

const swarm_init = tool({
  description: "Initialize swarm session and check tool availability",
  args: {
    project_path: tool.schema.string().optional().describe("Project path"),
    isolation: tool.schema
      .enum(["worktree", "reservation"])
      .optional()
      .describe(
        "Isolation mode: 'worktree' for git worktree isolation, 'reservation' for file reservations (default)",
      ),
  },
  execute: (args, ctx) => execTool("swarm_init", args, ctx),
});

const swarm_select_strategy = tool({
  description: "Analyze task and recommend decomposition strategy",
  args: {
    task: tool.schema.string().min(1).describe("Task to analyze"),
    codebase_context: tool.schema
      .string()
      .optional()
      .describe("Codebase context"),
  },
  execute: (args, ctx) => execTool("swarm_select_strategy", args, ctx),
});

const swarm_plan_prompt = tool({
  description: "Generate strategy-specific decomposition prompt",
  args: {
    task: tool.schema.string().min(1).describe("Task to decompose"),
    strategy: tool.schema
      .enum(["file-based", "feature-based", "risk-based", "auto"])
      .optional()
      .describe("Decomposition strategy"),
    max_subtasks: tool.schema
      .number()
      .int()
      .min(2)
      .max(10)
      .optional()
      .describe("Max subtasks"),
    context: tool.schema.string().optional().describe("Additional context"),
    query_cass: tool.schema
      .boolean()
      .optional()
      .describe("Query CASS for similar tasks"),
    cass_limit: tool.schema
      .number()
      .int()
      .min(1)
      .max(10)
      .optional()
      .describe("CASS limit"),
  },
  execute: (args, ctx) => execTool("swarm_plan_prompt", args, ctx),
});

const swarm_decompose = tool({
  description: "Generate decomposition prompt for breaking task into subtasks",
  args: {
    task: tool.schema.string().min(1).describe("Task to decompose"),
    max_subtasks: tool.schema
      .number()
      .int()
      .min(2)
      .max(10)
      .optional()
      .describe("Max subtasks"),
    context: tool.schema.string().optional().describe("Additional context"),
    query_cass: tool.schema.boolean().optional().describe("Query CASS"),
    cass_limit: tool.schema
      .number()
      .int()
      .min(1)
      .max(10)
      .optional()
      .describe("CASS limit"),
  },
  execute: (args, ctx) => execTool("swarm_decompose", args, ctx),
});

const swarm_validate_decomposition = tool({
  description: "Validate a decomposition response against CellTreeSchema",
  args: {
    response: tool.schema.string().describe("Decomposition response"),
  },
  execute: (args, ctx) => execTool("swarm_validate_decomposition", args, ctx),
});

const swarm_status = tool({
  description: "Get status of a swarm by epic ID",
  args: {
    epic_id: tool.schema.string().describe("Epic bead ID"),
    project_key: tool.schema.string().describe("Project key"),
  },
  execute: (args, ctx) => execTool("swarm_status", args, ctx),
});

const swarm_progress = tool({
  description: "Report progress on a subtask to coordinator",
  args: {
    project_key: tool.schema.string().describe("Project key"),
    agent_name: tool.schema.string().describe("Agent name"),
    bead_id: tool.schema.string().describe("Cell ID"),
    status: tool.schema
      .enum(["in_progress", "blocked", "completed", "failed"])
      .describe("Status"),
    message: tool.schema.string().optional().describe("Progress message"),
    progress_percent: tool.schema
      .number()
      .min(0)
      .max(100)
      .optional()
      .describe("Progress %"),
    files_touched: tool.schema
      .array(tool.schema.string())
      .optional()
      .describe("Files modified"),
  },
  execute: (args, ctx) => execTool("swarm_progress", args, ctx),
});

const swarm_complete = tool({
  description:
    "Mark subtask complete with Verification Gate. Runs UBS scan, typecheck, and tests before allowing completion.",
  args: {
    project_key: tool.schema.string().describe("Project key"),
    agent_name: tool.schema.string().describe("Agent name"),
    bead_id: tool.schema.string().describe("Cell ID"),
    summary: tool.schema.string().describe("Completion summary"),
    evaluation: tool.schema.string().optional().describe("Self-evaluation JSON"),
    files_touched: tool.schema
      .array(tool.schema.string())
      .optional()
      .describe("Files modified - will be verified"),
    skip_ubs_scan: tool.schema.boolean().optional().describe("Skip UBS scan"),
    skip_verification: tool.schema
      .boolean()
      .optional()
      .describe("Skip ALL verification (UBS, typecheck, tests)"),
    skip_review: tool.schema
      .boolean()
      .optional()
      .describe("Skip review gate check"),
  },
  execute: (args, ctx) => execTool("swarm_complete", args, ctx),
});

const swarm_record_outcome = tool({
  description: "Record subtask outcome for implicit feedback scoring",
  args: {
    bead_id: tool.schema.string().describe("Cell ID"),
    duration_ms: tool.schema.number().int().min(0).describe("Duration in ms"),
    error_count: tool.schema
      .number()
      .int()
      .min(0)
      .optional()
      .describe("Error count"),
    retry_count: tool.schema
      .number()
      .int()
      .min(0)
      .optional()
      .describe("Retry count"),
    success: tool.schema.boolean().describe("Whether task succeeded"),
    files_touched: tool.schema
      .array(tool.schema.string())
      .optional()
      .describe("Files modified"),
    criteria: tool.schema
      .array(tool.schema.string())
      .optional()
      .describe("Evaluation criteria"),
    strategy: tool.schema
      .enum(["file-based", "feature-based", "risk-based"])
      .optional()
      .describe("Strategy used"),
  },
  execute: (args, ctx) => execTool("swarm_record_outcome", args, ctx),
});

const swarm_subtask_prompt = tool({
  description: "Generate the prompt for a spawned subtask agent",
  args: {
    agent_name: tool.schema.string().describe("Agent name"),
    bead_id: tool.schema.string().describe("Cell ID"),
    epic_id: tool.schema.string().describe("Epic ID"),
    subtask_title: tool.schema.string().describe("Subtask title"),
    subtask_description: tool.schema
      .string()
      .optional()
      .describe("Description"),
    files: tool.schema.array(tool.schema.string()).describe("Files to work on"),
    shared_context: tool.schema.string().optional().describe("Shared context"),
  },
  execute: (args, ctx) => execTool("swarm_subtask_prompt", args, ctx),
});

const swarm_spawn_subtask = tool({
  description: "Prepare a subtask for spawning with Task tool",
  args: {
    bead_id: tool.schema.string().describe("Cell ID"),
    epic_id: tool.schema.string().describe("Epic ID"),
    subtask_title: tool.schema.string().describe("Subtask title"),
    subtask_description: tool.schema
      .string()
      .optional()
      .describe("Description"),
    files: tool.schema.array(tool.schema.string()).describe("Files to work on"),
    shared_context: tool.schema.string().optional().describe("Shared context"),
  },
  execute: (args, ctx) => execTool("swarm_spawn_subtask", args, ctx),
});

const swarm_complete_subtask = tool({
  description: "Handle subtask completion after Task agent returns",
  args: {
    bead_id: tool.schema.string().describe("Cell ID"),
    task_result: tool.schema.string().describe("Task result JSON"),
    files_touched: tool.schema
      .array(tool.schema.string())
      .optional()
      .describe("Files modified"),
  },
  execute: (args, ctx) => execTool("swarm_complete_subtask", args, ctx),
});

const swarm_evaluation_prompt = tool({
  description: "Generate self-evaluation prompt for a completed subtask",
  args: {
    bead_id: tool.schema.string().describe("Cell ID"),
    subtask_title: tool.schema.string().describe("Subtask title"),
    files_touched: tool.schema
      .array(tool.schema.string())
      .describe("Files modified"),
  },
  execute: (args, ctx) => execTool("swarm_evaluation_prompt", args, ctx),
});

const swarm_broadcast = tool({
  description:
    "Broadcast context update to all agents working on the same epic",
  args: {
    project_path: tool.schema.string().describe("Project path"),
    agent_name: tool.schema.string().describe("Agent name"),
    epic_id: tool.schema.string().describe("Epic ID"),
    message: tool.schema.string().describe("Context update message"),
    importance: tool.schema
      .enum(["info", "warning", "blocker"])
      .optional()
      .describe("Priority level (default: info)"),
    files_affected: tool.schema
      .array(tool.schema.string())
      .optional()
      .describe("Files this context relates to"),
  },
  execute: (args, ctx) => execTool("swarm_broadcast", args, ctx),
});

// =============================================================================
// Worktree Isolation Tools
// =============================================================================

const swarm_worktree_create = tool({
  description:
    "Create a git worktree for isolated task execution. Worker operates in worktree, not main branch.",
  args: {
    project_path: tool.schema.string().describe("Absolute path to project root"),
    task_id: tool.schema.string().describe("Task/bead ID (e.g., bd-abc123.1)"),
    start_commit: tool.schema
      .string()
      .describe("Commit SHA to create worktree at (swarm start point)"),
  },
  execute: (args, ctx) => execTool("swarm_worktree_create", args, ctx),
});

const swarm_worktree_merge = tool({
  description:
    "Cherry-pick commits from worktree back to main branch. Call after worker completes.",
  args: {
    project_path: tool.schema.string().describe("Absolute path to project root"),
    task_id: tool.schema.string().describe("Task/bead ID"),
    start_commit: tool.schema
      .string()
      .optional()
      .describe("Original start commit (to find new commits)"),
  },
  execute: (args, ctx) => execTool("swarm_worktree_merge", args, ctx),
});

const swarm_worktree_cleanup = tool({
  description:
    "Remove a worktree after completion or abort. Idempotent - safe to call multiple times.",
  args: {
    project_path: tool.schema.string().describe("Absolute path to project root"),
    task_id: tool.schema.string().optional().describe("Task/bead ID to clean up"),
    cleanup_all: tool.schema
      .boolean()
      .optional()
      .describe("Remove all worktrees for this project"),
  },
  execute: (args, ctx) => execTool("swarm_worktree_cleanup", args, ctx),
});

const swarm_worktree_list = tool({
  description: "List all active worktrees for a project",
  args: {
    project_path: tool.schema.string().describe("Absolute path to project root"),
  },
  execute: (args, ctx) => execTool("swarm_worktree_list", args, ctx),
});

// =============================================================================
// Structured Review Tools
// =============================================================================

const swarm_review = tool({
  description:
    "Generate a review prompt for a completed subtask. Includes epic context, dependencies, and diff.",
  args: {
    project_key: tool.schema.string().describe("Project path"),
    epic_id: tool.schema.string().describe("Epic bead ID"),
    task_id: tool.schema.string().describe("Subtask bead ID to review"),
    files_touched: tool.schema
      .array(tool.schema.string())
      .optional()
      .describe("Files modified (will get diff for these)"),
  },
  execute: (args, ctx) => execTool("swarm_review", args, ctx),
});

const swarm_review_feedback = tool({
  description:
    "Send review feedback to a worker. Tracks attempts (max 3). Fails task after 3 rejections.",
  args: {
    project_key: tool.schema.string().describe("Project path"),
    task_id: tool.schema.string().describe("Subtask bead ID"),
    worker_id: tool.schema.string().describe("Worker agent name"),
    status: tool.schema
      .enum(["approved", "needs_changes"])
      .describe("Review status"),
    summary: tool.schema.string().optional().describe("Review summary"),
    issues: tool.schema
      .string()
      .optional()
      .describe("JSON array of ReviewIssue objects (for needs_changes)"),
  },
  execute: (args, ctx) => execTool("swarm_review_feedback", args, ctx),
});

// =============================================================================
    // Skills Management Tools
    // NOTE: Skills are now managed by OpenCode native format (.opencode/skill/)
    // Use `use skill <name>` syntax instead of deprecated skills_* tools
    skills_create,
      skills_update,
      skills_delete,
      skills_init,
      skills_add_script,
      skills_execute,
      // Swarm Insights
      swarm_get_strategy_insights,
      swarm_get_file_insights,
      swarm_get_pattern_insights,
      // CASS (Cross-Agent Session Search)
      cass_search,
      cass_view,
      cass_expand,
      cass_health,
      cass_index,
      cass_stats,
    },

    // Swarm-aware compaction hook with LLM-powered continuation prompts
    // Three-level fallback chain: LLM → static context → detection fallback → none
    "experimental.session.compacting": async (
      input: { sessionID: string },
      output: CompactionOutput,
    ) => {
      const startTime = Date.now();
      
      // =======================================================================
      // LOG: Compaction hook invoked - capture EVERYTHING we receive
      // =======================================================================
      logCompaction("info", "compaction_hook_invoked", {
        session_id: input.sessionID,
        project_directory: projectDirectory,
        input_keys: Object.keys(input),
        input_full: JSON.parse(JSON.stringify(input)), // Deep clone for logging
        output_keys: Object.keys(output),
        output_context_count: output.context?.length ?? 0,
        output_has_prompt_field: "prompt" in output,
        output_initial_state: {
          context: output.context,
          prompt: (output as any).prompt,
        },
        env: {
          OPENCODE_SESSION_ID: process.env.OPENCODE_SESSION_ID,
          OPENCODE_MESSAGE_ID: process.env.OPENCODE_MESSAGE_ID,
          OPENCODE_AGENT: process.env.OPENCODE_AGENT,
          OPENCODE_LITE_MODEL: process.env.OPENCODE_LITE_MODEL,
          SWARM_PROJECT_DIR: process.env.SWARM_PROJECT_DIR,
        },
        cwd: process.cwd(),
        timestamp: new Date().toISOString(),
      });

      // =======================================================================
      // STEP 1: Scan session messages for swarm tool calls
      // =======================================================================
      const sessionScanStart = Date.now();
      const sessionScan = await scanSessionMessages(input.sessionID);
      const sessionScanDuration = Date.now() - sessionScanStart;

      logCompaction("info", "session_scan_results", {
        session_id: input.sessionID,
        duration_ms: sessionScanDuration,
        message_count: sessionScan.messageCount,
        tool_call_count: sessionScan.toolCalls.length,
        swarm_detected_from_messages: sessionScan.swarmDetected,
        reasons: sessionScan.reasons,
      });

      // =======================================================================
      // STEP 2: Detect swarm state from hive cells
      // =======================================================================
      const detectionStart = Date.now();
      const detection = await detectSwarm();
      const detectionDuration = Date.now() - detectionStart;

      logCompaction("info", "swarm_detection_complete", {
        session_id: input.sessionID,
        duration_ms: detectionDuration,
        detected: detection.detected,
        confidence: detection.confidence,
        reasons: detection.reasons,
        reason_count: detection.reasons.length,
      });

      // =======================================================================
      // STEP 3: Merge session scan with hive detection for final confidence
      // =======================================================================
      // If session messages show high-confidence swarm tools, boost confidence
      if (sessionScan.swarmDetected && sessionScan.reasons.some(r => r.includes("high-confidence"))) {
        if (detection.confidence === "none" || detection.confidence === "low") {
          detection.confidence = "high";
          detection.detected = true;
          detection.reasons.push(...sessionScan.reasons);
          
          logCompaction("info", "confidence_boost_from_session_scan", {
            session_id: input.sessionID,
            original_confidence: detection.confidence,
            boosted_to: "high",
            session_reasons: sessionScan.reasons,
          });
        }
      } else if (sessionScan.swarmDetected) {
        // Medium boost for any swarm tools found
        if (detection.confidence === "none") {
          detection.confidence = "medium";
          detection.detected = true;
          detection.reasons.push(...sessionScan.reasons);

          logCompaction("info", "confidence_boost_from_session_scan", {
            session_id: input.sessionID,
            original_confidence: "none",
            boosted_to: "medium",
            session_reasons: sessionScan.reasons,
          });
        } else if (detection.confidence === "low") {
          detection.confidence = "medium";
          detection.reasons.push(...sessionScan.reasons);

          logCompaction("info", "confidence_boost_from_session_scan", {
            session_id: input.sessionID,
            original_confidence: "low",
            boosted_to: "medium",
            session_reasons: sessionScan.reasons,
          });
        }
      }

      logCompaction("info", "final_swarm_detection", {
        session_id: input.sessionID,
        confidence: detection.confidence,
        detected: detection.detected,
        combined_reasons: detection.reasons,
        message_scan_contributed: sessionScan.swarmDetected,
      });

      if (detection.confidence === "high" || detection.confidence === "medium") {
        // Definite or probable swarm - try LLM-powered compaction
        logCompaction("info", "swarm_detected_attempting_llm", {
          session_id: input.sessionID,
          confidence: detection.confidence,
          reasons: detection.reasons,
        });

        try {
          // Level 1: Query actual state
          const queryStart = Date.now();
          const snapshot = await querySwarmState(input.sessionID);
          const queryDuration = Date.now() - queryStart;

          logCompaction("info", "swarm_state_queried", {
            session_id: input.sessionID,
            duration_ms: queryDuration,
            has_epic: !!snapshot.epic,
            epic_id: snapshot.epic?.id,
            epic_title: snapshot.epic?.title,
            epic_status: snapshot.epic?.status,
            subtask_count: snapshot.epic?.subtasks?.length ?? 0,
            subtasks: snapshot.epic?.subtasks?.map(s => ({
              id: s.id,
              title: s.title,
              status: s.status,
              file_count: s.files?.length ?? 0,
            })),
            message_count: snapshot.messages?.length ?? 0,
            reservation_count: snapshot.reservations?.length ?? 0,
            detection_confidence: snapshot.detection.confidence,
            detection_reasons: snapshot.detection.reasons,
            full_snapshot: snapshot, // Log the entire snapshot
          });

          // =======================================================================
          // CAPTURE POINT 1: Detection complete - record confidence and reasons
          // =======================================================================
          await captureCompaction(
            input.sessionID,
            snapshot.epic?.id || "unknown",
            "detection_complete",
            {
              confidence: snapshot.detection.confidence,
              detected: detection.detected,
              reasons: snapshot.detection.reasons,
              session_scan_contributed: sessionScan.swarmDetected,
              session_scan_reasons: sessionScan.reasons,
              epic_id: snapshot.epic?.id,
              epic_title: snapshot.epic?.title,
              subtask_count: snapshot.epic?.subtasks?.length ?? 0,
            },
          );

          // Level 2: Generate prompt with LLM
          const llmStart = Date.now();
          const llmPrompt = await generateCompactionPrompt(snapshot);
          const llmDuration = Date.now() - llmStart;

          logCompaction("info", "llm_generation_complete", {
            session_id: input.sessionID,
            duration_ms: llmDuration,
            success: !!llmPrompt,
            prompt_length: llmPrompt?.length ?? 0,
            prompt_preview: llmPrompt?.substring(0, 500),
          });

          // =======================================================================
          // CAPTURE POINT 2: Prompt generated - record FULL prompt content
          // =======================================================================
          if (llmPrompt) {
            await captureCompaction(
              input.sessionID,
              snapshot.epic?.id || "unknown",
              "prompt_generated",
              {
                prompt_length: llmPrompt.length,
                full_prompt: llmPrompt, // FULL content, not truncated
                context_type: "llm_generated",
                duration_ms: llmDuration,
              },
            );
          }

          if (llmPrompt) {
            // SUCCESS: Use LLM-generated prompt
            const header = `[Swarm compaction: LLM-generated, ${detection.reasons.join(", ")}]\n\n`;
            const fullContent = header + llmPrompt;

            // Progressive enhancement: use new API if available
            if ("prompt" in output) {
              output.prompt = fullContent;
              logCompaction("info", "context_injected_via_prompt_api", {
                session_id: input.sessionID,
                content_length: fullContent.length,
                method: "output.prompt",
              });
            } else {
              output.context.push(fullContent);
              logCompaction("info", "context_injected_via_context_array", {
                session_id: input.sessionID,
                content_length: fullContent.length,
                method: "output.context.push",
                context_count_after: output.context.length,
              });
            }

            // =======================================================================
            // CAPTURE POINT 3a: Context injected (LLM path) - record FULL content
            // =======================================================================
            await captureCompaction(
              input.sessionID,
              snapshot.epic?.id || "unknown",
              "context_injected",
              {
                full_content: fullContent, // FULL content, not truncated
                content_length: fullContent.length,
                injection_method: "prompt" in output ? "output.prompt" : "output.context.push",
                context_type: "llm_generated",
              },
            );

            const totalDuration = Date.now() - startTime;
            logCompaction("info", "compaction_complete_llm_success", {
              session_id: input.sessionID,
              total_duration_ms: totalDuration,
              detection_duration_ms: detectionDuration,
              query_duration_ms: queryDuration,
              llm_duration_ms: llmDuration,
              confidence: detection.confidence,
              context_type: "llm_generated",
              content_length: fullContent.length,
            });
            return;
          }

          // LLM failed, fall through to static prompt
          logCompaction("warn", "llm_generation_returned_null", {
            session_id: input.sessionID,
            llm_duration_ms: llmDuration,
            falling_back_to: "static_prompt",
          });
        } catch (err) {
          // LLM failed, fall through to static prompt
          logCompaction("error", "llm_generation_failed", {
            session_id: input.sessionID,
            error: err instanceof Error ? err.message : String(err),
            error_stack: err instanceof Error ? err.stack : undefined,
            falling_back_to: "static_prompt",
          });
        }

        // Level 3: Fall back to static context
        const header = `[Swarm detected: ${detection.reasons.join(", ")}]\n\n`;
        const staticContent = header + SWARM_COMPACTION_CONTEXT;
        output.context.push(staticContent);

        // =======================================================================
        // CAPTURE POINT 3b: Context injected (static fallback) - record FULL content
        // =======================================================================
        await captureCompaction(
          input.sessionID,
          "unknown", // No snapshot available in this path
          "context_injected",
          {
            full_content: staticContent,
            content_length: staticContent.length,
            injection_method: "output.context.push",
            context_type: "static_swarm_context",
          },
        );

        const totalDuration = Date.now() - startTime;
        logCompaction("info", "compaction_complete_static_fallback", {
          session_id: input.sessionID,
          total_duration_ms: totalDuration,
          confidence: detection.confidence,
          context_type: "static_swarm_context",
          content_length: staticContent.length,
          context_count_after: output.context.length,
        });
      } else if (detection.confidence === "low") {
        // Level 4: Possible swarm - inject fallback detection prompt
        const header = `[Possible swarm: ${detection.reasons.join(", ")}]\n\n`;
        const fallbackContent = header + SWARM_DETECTION_FALLBACK;
        output.context.push(fallbackContent);

        // =======================================================================
        // CAPTURE POINT 3c: Context injected (detection fallback) - record FULL content
        // =======================================================================
        await captureCompaction(
          input.sessionID,
          "unknown", // No snapshot for low confidence
          "context_injected",
          {
            full_content: fallbackContent,
            content_length: fallbackContent.length,
            injection_method: "output.context.push",
            context_type: "detection_fallback",
          },
        );

        const totalDuration = Date.now() - startTime;
        logCompaction("info", "compaction_complete_detection_fallback", {
          session_id: input.sessionID,
          total_duration_ms: totalDuration,
          confidence: detection.confidence,
          context_type: "detection_fallback",
          content_length: fallbackContent.length,
          context_count_after: output.context.length,
          reasons: detection.reasons,
        });
      } else {
        // Level 5: confidence === "none" - no injection, probably not a swarm
        const totalDuration = Date.now() - startTime;
        logCompaction("info", "compaction_complete_no_swarm", {
          session_id: input.sessionID,
          total_duration_ms: totalDuration,
          confidence: detection.confidence,
          context_type: "none",
          reasons: detection.reasons,
          context_count_unchanged: output.context.length,
        });
      }

      // =======================================================================
      // LOG: Final output state
      // =======================================================================
      logCompaction("debug", "compaction_hook_complete_final_state", {
        session_id: input.sessionID,
        output_context_count: output.context?.length ?? 0,
        output_context_lengths: output.context?.map(c => c.length) ?? [],
        output_has_prompt: !!(output as any).prompt,
        output_prompt_length: (output as any).prompt?.length ?? 0,
        total_duration_ms: Date.now() - startTime,
      });
    },
  };
};

export default SwarmPlugin;
